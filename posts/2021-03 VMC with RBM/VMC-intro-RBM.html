<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.242">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Borja Requena">
<meta name="dcterms.date" content="2021-03-24">
<meta name="description" content="We introduce the variational Monte Carlo technique to study quantum many-body systems using neural networks to represent the many-body quantum states. All from scratch!">

<title>Borja Requena - Introduction to variational Monte Carlo with neural network quantum states</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Borja Requena</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/BorjaRequena"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/BorjaRequena"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Introduction to variational Monte Carlo with neural network quantum states</h1>
                  <div>
        <div class="description">
          We introduce the variational Monte Carlo technique to study quantum many-body systems using neural networks to represent the many-body quantum states. All from scratch!
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Monte Carlo</div>
                <div class="quarto-category">Machine Learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Borja Requena </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 24, 2021</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#monte-carlo-integration" id="toc-monte-carlo-integration" class="nav-link active" data-scroll-target="#monte-carlo-integration">Monte Carlo Integration</a>
  <ul class="collapse">
  <li><a href="#energy-expectation-of-a-quantum-system" id="toc-energy-expectation-of-a-quantum-system" class="nav-link" data-scroll-target="#energy-expectation-of-a-quantum-system">Energy expectation of a quantum system</a></li>
  </ul></li>
  <li><a href="#importance-sampling" id="toc-importance-sampling" class="nav-link" data-scroll-target="#importance-sampling">Importance Sampling</a>
  <ul class="collapse">
  <li><a href="#metropolis-hastings-for-quantum-systems" id="toc-metropolis-hastings-for-quantum-systems" class="nav-link" data-scroll-target="#metropolis-hastings-for-quantum-systems">Metropolis-Hastings for quantum systems</a></li>
  </ul></li>
  <li><a href="#example---monte-carlo-integration" id="toc-example---monte-carlo-integration" class="nav-link" data-scroll-target="#example---monte-carlo-integration">Example - Monte Carlo Integration</a></li>
  <li><a href="#statistical-analysis-and-autocorrelation-time" id="toc-statistical-analysis-and-autocorrelation-time" class="nav-link" data-scroll-target="#statistical-analysis-and-autocorrelation-time">Statistical analysis and autocorrelation time</a>
  <ul class="collapse">
  <li><a href="#binning-analysis" id="toc-binning-analysis" class="nav-link" data-scroll-target="#binning-analysis">Binning analysis</a></li>
  </ul></li>
  <li><a href="#example---binning-analysis" id="toc-example---binning-analysis" class="nav-link" data-scroll-target="#example---binning-analysis">Example - Binning analysis</a></li>
  <li><a href="#monte-carlo-optimization" id="toc-monte-carlo-optimization" class="nav-link" data-scroll-target="#monte-carlo-optimization">Monte Carlo optimization</a></li>
  <li><a href="#example---monte-carlo-optimization" id="toc-example---monte-carlo-optimization" class="nav-link" data-scroll-target="#example---monte-carlo-optimization">Example - Monte Carlo optimization</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="monte-carlo-integration" class="level2">
<h2 class="anchored" data-anchor-id="monte-carlo-integration">Monte Carlo Integration</h2>
<p>The main power of Monte Carlo methods comes from the capability of computing high-dimensional integrals in large spaces. In physics, this allows us to compute expectation values of the form <span class="math display">\[\langle f\rangle = \int dx p(x)f(x) \ \ \ \text{or} \ \ \ \langle f \rangle = \sum_{x} p(x)f(x)\]</span> for continuous and discrete sytems, respectively. Where <span class="math inline">\(p\)</span> is the probability distribution over states <span class="math inline">\(x\)</span> and <span class="math inline">\(f\)</span> is a function of the state, such as its corresponding energy.</p>
<p>Physics is benevolent and, generally, the systems of interest only span a tiny bit of their phase space, meaning that <span class="math inline">\(p(x)\simeq 0\)</span> for most states <span class="math inline">\(x\)</span> and, therefore, most of the terms in the previous sum have a meaningless contribution. With Monte Carlo, rather than accounting for all the possible states <span class="math inline">\(x\)</span>, we approximate the expectation value by sampling from <span class="math inline">\(p(x)\)</span>. Hence, <span class="math display">\[\langle f \rangle \approx \frac{1}{N}\sum_{i=1}^Nf(x_i),\]</span> where <span class="math inline">\(x_i\)</span> are sampled according to <span class="math inline">\(p(x)\)</span>. This is called importance sampling and it allows us to obtain reasonably good approximations with a limitted amount of samples.</p>
<section id="energy-expectation-of-a-quantum-system" class="level3">
<h3 class="anchored" data-anchor-id="energy-expectation-of-a-quantum-system">Energy expectation of a quantum system</h3>
<p>In quantum phsyics, a quantity of utmost interest is the expected value of the energy of a system under the action of a Hamiltonian <span class="math inline">\(H\)</span> and a wave function <span class="math inline">\(\Psi(x)\)</span> in a given basis <span class="math inline">\(x\)</span> <span class="math display">\[\langle H \rangle = \frac{\langle\Psi^*|H|\Psi\rangle}{\langle \Psi|\Psi\rangle} = \frac{\int dx\Psi^*(x)H\Psi(x)}{\int dx\Psi^*(x)\Psi(x)}.\]</span></p>
<p>From now on, we will omit the dependency on the state and denote <span class="math inline">\(\Psi\equiv\Psi(x)\)</span> unless needed for clarification. By introducing a term <span class="math inline">\(\frac{\Psi}{\Psi}\)</span> into the numerator, we can rewrite the integral in a convenient way for Monte Carlo integration <span class="math display">\[\langle H \rangle = \frac{\int \Psi^*\frac{\Psi}{\Psi}H\Psi}{\int \Psi^*\Psi} = \frac{\int |\Psi|^2 \frac{H\Psi}{\Psi}}{\int |\Psi|^2} = \int \rho E_L,\]</span> where <span class="math inline">\(\rho=\frac{|\Psi|^2}{\int|\Psi|^2}\)</span> is the probability density and <span class="math inline">\(E_L=\frac{H\Psi}{\Psi}\)</span> is the so-called <strong>local energy</strong>.</p>
<p>Hence, the expected energy can be computed via Monte Carlo integration as the expectation value of the local energy over the probability distribution <span class="math inline">\(\rho=\frac{|\Psi|^2}{\int|\Psi|^2}\)</span>, such that <span class="math display">\[\langle H\rangle \approx \frac{1}{N}\sum_{k=1}^NE_L(x_k)\]</span></p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math inline">\(x\)</span> can be any convenient basis for the given problem at hand, it does not refer to position. In the example case that we will be solving in this tutorial, we take the basis <span class="math inline">\(\sigma^z\)</span> for a spin system.</p>
</div>
</div>
</section>
</section>
<section id="importance-sampling" class="level2">
<h2 class="anchored" data-anchor-id="importance-sampling">Importance Sampling</h2>
<p>One of the most important aspects for Monte Carlo integration is the way that importance sampling is done. Markov Chain Monte Carlo (MCMC) is an efficient approach to perform sampling in many dimensions when the probability density <span class="math inline">\(p(x)\)</span> is dominated by a small part of the whole state space.</p>
<p>Samples are drawn iteratively, forming a Markov Chain, starting from any given state. In order to properly compute the expected value, the Markov Chain needs to converge to the <strong>stationary distribution</strong> <span class="math inline">\(p(x)\)</span> regardless of the initial state.</p>
<p>Let <span class="math inline">\(t(x\rightarrow x')\)</span> be the probability to transition from state <span class="math inline">\(x\)</span> to <span class="math inline">\(x'\)</span> such that <span class="math inline">\(\sum_{x'}t(x\rightarrow x')=1\)</span>, and <span class="math inline">\(p_s(x)\)</span> the probability to be in state <span class="math inline">\(x\)</span> at step <span class="math inline">\(s\)</span>. Then, <span class="math inline">\(p_{s+1}(x) = \sum_{x'}p_s(x')t(x'\rightarrow x)\)</span>. A stationary probability is obtained when <span class="math inline">\(p_s(x)\)</span> is independent of the step and, therefore, <span class="math display">\[p(x) = \sum_{x'}p(x')t(x'\rightarrow x).\]</span></p>
<p>If a Markov chain is irreducible, the stationary distribution is unique and, if it is also aperiodic, it converges to it. A sufficient condition for stationarity is satsifying the <strong>detailed balance condition</strong> <span class="math inline">\(p(x)t(x\rightarrow x') = p(x')t(x'\rightarrow x)\)</span>.</p>
<p>The <strong>Metropolis-Hastings</strong> algorithm {% cite HastingsBiometrika1970%} is built to satisfy detailed balance. This is a very simple algorithm in which we split the transition probability <span class="math inline">\(t(x\rightarrow x')\)</span> into two factors: the probability to propose or choose the next state <span class="math inline">\(c(x\rightarrow x')\)</span> and the probability to accept the next state <span class="math inline">\(a(x\rightarrow x')\)</span> such that <span class="math display">\[t(x\rightarrow x') = c(x\rightarrow x')a(x\rightarrow x').\]</span> Detailed balance is fulfilled by taking <span class="math inline">\(a(x\rightarrow x')=\min\left\{1, \frac{p(x')}{p(x)}\frac{c(x'\rightarrow x)}{c(x\rightarrow x')}\right\}\)</span>.</p>
<p>Generally, the probability to propose a state is symmetric <span class="math inline">\(c(x\rightarrow x')=c(x'\rightarrow x)\)</span>, as it can be, for instance, the case of randomly flipping a spin in a lattice. In these cases, the acceptance probability is simplified <span class="math display">\[a(x\rightarrow x') = \min\left\{1, \frac{p(x')}{p(x)}\right\}.\]</span></p>
<p>A Markov Chain is generated by iterating over the following two steps: 1. With a state <span class="math inline">\(x\)</span>, propose a new state <span class="math inline">\(x'\)</span> with probability <span class="math inline">\(c(x\rightarrow x')\)</span> 2. Accept <span class="math inline">\(x'\)</span> with probability <span class="math inline">\(a(x\rightarrow x')\)</span>. If rejected, the next state is <span class="math inline">\(x\)</span>.</p>
<p>The time it takes for the Markov Chain to converge to the stationary distribution is called <strong>thermalisation</strong>. In other words, thermalisation is the time it takes to the Markov Chain to forget its initial state. With MCMC we need to wait for the thermalisation to finish before we can start drawing samples from the desired probability distribution. These samples, though, will be highly correlated between one another, thus requiring careful error analysis to be properly handled. We will deal with this later on.</p>
<section id="metropolis-hastings-for-quantum-systems" class="level3">
<h3 class="anchored" data-anchor-id="metropolis-hastings-for-quantum-systems">Metropolis-Hastings for quantum systems</h3>
<p>As it was previously introduced, the expectation value of the energy can be obtained by sampling configurations according to the distribution <span class="math inline">\(\rho=\frac{|\Psi|^2}{\int|\Psi|^2}\)</span>. Hence, we want to create a Markov Chain that converges to the stationary distribution <span class="math inline">\(\rho\)</span> and, therefore, the acceptance probabilities need to be defined accordingly <span class="math display">\[a(x\rightarrow x') = \min\left\{
1, \frac{\rho(x')}{\rho(x)}\right\} = \min\left\{1, \frac{|\Psi(x')|^2}{|\Psi(x)|^2}\right\}.\]</span> Notice that the normalisation factor <span class="math inline">\(\int|\Psi|^2\)</span> cancels out. Thus, we never have to worry about normalising probabilities, which would, most times, make the computation intractable.</p>
</section>
</section>
<section id="example---monte-carlo-integration" class="level2">
<h2 class="anchored" data-anchor-id="example---monte-carlo-integration">Example - Monte Carlo Integration</h2>
<p>With this, we have the tools to compute the expectation value of an observable of a quantum many-body system. As an example, we will take the quantum Ising spin model <span class="math display">\[H = J\sum_{i=1}^{n-1}\sigma_{i}^z\sigma_{i+1}^z + B\sum_{i=1}^n\sigma_{i}^x,\]</span> where <span class="math inline">\(\sigma_i^z, \sigma_i^x\)</span> are the Pauli matrices acting on the <span class="math inline">\(i\)</span>-th site, with open boundary conditions.</p>
<p>The only thing that is missing is a trial wave function <span class="math inline">\(\Psi\)</span> to perform the sampling. We will take the Restricted Boltzmann Machine (RBM) ansatz, as introduced in {% cite CarleoScience2017%}, of the form <span class="math display">\[\Psi(x) = e^{b^Tx}\prod_{i=1}^{n_h}2\cosh(c_i + W_{i\cdot}x),\]</span> where <span class="math inline">\(b, c, W\)</span> are the visible biases, hidden biases and weight matrix, respectively, and <span class="math inline">\(n_h\)</span> denotes the number of hidden units.</p>
<p>For now, we can just take this as a functional ansatz without diving much further into RBMs. The only thing that we need to know is that RBMs have two layers: a visible and a hidden layer. The visible layer corresponds to the physical system, while the hidden layer provides a set of auxiliary parameters that mediate the interaction between physical units. Therefore, the size of the visible layer is fixed by our problem and we need to choose the size of the hidden layer <span class="math inline">\(n_h\)</span>. The higher <span class="math inline">\(n_h\)</span>, the higher the representability of the ansatz, at the cost of more expensive computations. Since RBMs are universal approximators, we can always improve our solution by increasing <span class="math inline">\(n_h\)</span>.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The code is by no means optimized. In fact, almost everything here presented is <em>very</em> suboptimal. It is meant to be easily readable and resemble the equations as much as possible, in order to provide an idea of the overall procedure.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RBM:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Super simple implementation of an RBM with complex parameters."</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_visible, n_hidden):</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_visible <span class="op">=</span> n_visible</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_hidden <span class="op">=</span> n_hidden</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reset()</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> reset(<span class="va">self</span>):</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">"Reinitializes the complex parameters at random."</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        b <span class="op">=</span> np.random.randn(<span class="va">self</span>.n_visible) <span class="op">+</span> <span class="ot">1j</span><span class="op">*</span>np.random.randn(<span class="va">self</span>.n_visible) <span class="co"># visible bias</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        c <span class="op">=</span> np.random.randn(<span class="va">self</span>.n_hidden) <span class="op">+</span> <span class="ot">1j</span><span class="op">*</span>np.random.random(<span class="va">self</span>.n_hidden)  <span class="co"># hidden bias</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        W <span class="op">=</span> (np.random.randn(<span class="va">self</span>.n_hidden, <span class="va">self</span>.n_visible) <span class="op">+</span> </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>             <span class="ot">1j</span><span class="op">*</span>np.random.randn(<span class="va">self</span>.n_hidden, <span class="va">self</span>.n_visible))                  <span class="co"># weights</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.params <span class="op">=</span> np.concatenate((b, c, W.ravel())) <span class="op">/</span> <span class="dv">10</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> b(<span class="va">self</span>): <span class="cf">return</span> <span class="va">self</span>.params[:<span class="va">self</span>.n_visible]</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> c(<span class="va">self</span>): <span class="cf">return</span> <span class="va">self</span>.params[<span class="va">self</span>.n_visible:<span class="va">self</span>.n_visible<span class="op">+</span><span class="va">self</span>.n_hidden]</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> W(<span class="va">self</span>): <span class="cf">return</span> np.reshape(<span class="va">self</span>.params[<span class="va">self</span>.n_visible<span class="op">+</span><span class="va">self</span>.n_hidden:], </span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>                                   (<span class="va">self</span>.n_hidden, <span class="va">self</span>.n_visible))</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> p(<span class="va">self</span>, v):</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>        <span class="co">"Probability amplitude of a visible state `v`. We don't need it for Monte Carlo."</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.exp(np.conj(<span class="va">self</span>.b) <span class="op">@</span> v)<span class="op">*</span>np.prod(np.cosh(<span class="va">self</span>.c <span class="op">+</span> <span class="va">self</span>.W <span class="op">@</span> v))<span class="op">*</span><span class="dv">2</span><span class="op">**</span><span class="va">self</span>.n_hidden</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> p_ratio(<span class="va">self</span>, v1, v2):</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        <span class="co">"Probability ratio between state `v2` and reference `v1`"</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>        f1 <span class="op">=</span> np.cosh(<span class="va">self</span>.c <span class="op">+</span> <span class="va">self</span>.W <span class="op">@</span> v1)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>        f2 <span class="op">=</span> np.cosh(<span class="va">self</span>.c <span class="op">+</span> <span class="va">self</span>.W <span class="op">@</span> v2)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>        log_diff <span class="op">=</span> np.conj(<span class="va">self</span>.b) <span class="op">@</span> (v2<span class="op">-</span>v1) <span class="op">+</span> <span class="bu">sum</span>(np.log(f2<span class="op">/</span>f1)) <span class="co"># log of ratio for numerical stability</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> np.exp(log_diff)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> p_ratios(<span class="va">self</span>, v1, v2):</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>        <span class="co">"Probability ratio between list of states `v2` and reference state `v1`."</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [<span class="va">self</span>.p_ratio(v1, v) <span class="cf">for</span> v <span class="kw">in</span> v2] </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let us define the physical system by choosing the number of spins, the coefficients of the Hamiltonian and the parameters of our wave function. For now, provided that we need a starting point for our trial wave function, we simply take a set of random parameters for our RBM ansatz.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">7</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">10</span>         <span class="co"># Number of spins</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>J, B <span class="op">=</span> <span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">1</span>  <span class="co"># Hamiltonian</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>n_visible, n_hidden <span class="op">=</span> n, <span class="dv">2</span><span class="op">*</span>n    <span class="co"># RBM size: twice as many hidden neurons</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>psi <span class="op">=</span> RBM(n_visible, n_hidden)  <span class="co"># Randomly initialize our anstaz</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With this, we define some functions to make our code more readable.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> local_energy(x, psi):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Local energy of Ising spin model."</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Interaction term</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    couplings <span class="op">=</span> (x[:<span class="op">-</span><span class="dv">1</span>]<span class="op">==</span>x[<span class="dv">1</span>:])<span class="op">*</span><span class="dv">2</span><span class="op">-</span><span class="dv">1</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    e_interaction <span class="op">=</span> J<span class="op">*</span><span class="bu">sum</span>(couplings)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Transverse field</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    states_with_flip <span class="op">=</span> [flip(x, i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(x))]</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    e_field <span class="op">=</span> B<span class="op">*</span><span class="bu">sum</span>(psi.p_ratios(x, states_with_flip))</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> e_interaction <span class="op">+</span> e_field </span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> flip(x, i):</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">"flips i-th bit of x"</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    xflip <span class="op">=</span> deepcopy(x)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    xflip[i] <span class="op">=</span> <span class="dv">1</span><span class="op">-</span>xflip[i]</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> xflip</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And now we are ready to do the Monte Carlo integration. When dealing with spins, new states are obtained by flipping spins, so we need to choose the total amount of samples to draw <code>n_samples</code> and the amount of spin flips <code>n_flips</code> performed to propose a new configuration.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">50000</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>n_flips <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>state <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">2</span>, n) <span class="co"># initial random state</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>states, energies <span class="op">=</span> [], []</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> tqdm(<span class="bu">range</span>(n_samples)):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sample new state</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    spin_idx <span class="op">=</span> np.random.randint(<span class="dv">0</span>, n, n_flips) </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    new_state <span class="op">=</span> flip(state, spin_idx)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> np.random.random() <span class="op">&lt;=</span> np.<span class="bu">abs</span>(psi.p_ratio(state, new_state))<span class="op">**</span><span class="dv">2</span>:</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        state <span class="op">=</span> deepcopy(new_state)   <span class="co"># Accept new state</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    states.append(state)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    energies.append(np.real(local_energy(state, psi)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt.plot(energies[:<span class="dv">1000</span>]) <span class="co"># Plot some</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>plt.tick_params(labelsize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Local energy"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Sample"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"E = </span><span class="sc">{</span>np<span class="sc">.</span>mean(energies)<span class="sc">:.4f}</span><span class="ss"> +- </span><span class="sc">{</span>np<span class="sc">.</span>std(energies)<span class="op">/</span>np<span class="sc">.</span>sqrt(n_samples)<span class="sc">:.4f}</span><span class="ss">"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="VMC-intro-RBM_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>With this random wave function, we do not observe any thermalisation. The result is the expected energy obtained with our wave function ansatz. Later on, we will see how to optimize its parameters to find the ground state energy.</p>
</section>
<section id="statistical-analysis-and-autocorrelation-time" class="level2">
<h2 class="anchored" data-anchor-id="statistical-analysis-and-autocorrelation-time">Statistical analysis and autocorrelation time</h2>
<p>Because of the nature of Markov chains, measurements are always correlated to a certain degree. Given that new states are obtained by modifying the previous ones, consecutive states can be highly correlated, although the correlation fades as the number of steps between states increases. The distance at which we can consider two states to be uncorrlated in the Markov chain is the <strong>autocorrelation time</strong> <span class="math inline">\(\tau\)</span>.</p>
<p>The statistical error <span class="math inline">\(\epsilon\)</span> is obtained via <span class="math display">\[\epsilon = \sqrt{\frac{s_f^2}{N}}, \ s_f^2 = \frac{1}{N-1}\sum_{i=1}^N\left(f(X_i) - \langle f \rangle\right)^2.\]</span> These quantities, however, are well defined for uncorrelated samples. Hence, knowing the autocorrelation time <span class="math inline">\(\tau\)</span>, we can compute our estimation values by exclusively taking samples every <span class="math inline">\(\tau\)</span> (or <span class="math inline">\(\geq\tau\)</span>) steps.</p>
<section id="binning-analysis" class="level3">
<h3 class="anchored" data-anchor-id="binning-analysis">Binning analysis</h3>
<p>Knowing the autocorrelation time is extremely important. However, finding the autocorrelation function is too costful and difficult to analyse so, in practice, we rely in the binning analysis of the time series to estimate both <span class="math inline">\(\tau\)</span> and <span class="math inline">\(\epsilon\)</span>. The main idea is that averages over chunks of the time-series, which are longer than the autocorrelation time, are independent of each other, thus providing the right error estimates.</p>
<p>Provided that we do not have any prior knowledge about the autocorrelation time, we have to use blocks of increasing lengths until the error estimate converges. We cut the time series into <span class="math inline">\(N_B\)</span> blocks of fixed length <span class="math inline">\(k\)</span> for several values of <span class="math inline">\(k=2^0,2^1, 2^2, \dots\)</span> With this, we can compute the block average of the <span class="math inline">\(i\)</span>-th block <span class="math display">\[\langle f \rangle_{B_i}=\frac{1}{k}\sum_{t=1}^kf(x_{(i-1)k+t}).\]</span> All the blocks have a mean <span class="math display">\[\langle f\rangle_B = \frac{1}{N_B}\sum_{i=1}^{N_B}\langle f\rangle_{B_i},\]</span> which, when the block length <span class="math inline">\(k\)</span> is larger than the autocorrelation time <span class="math inline">\(\tau\)</span>, allows us to compute the squared statistical error <span class="math display">\[\epsilon^2\approx\frac{s_B^2}{N_B}=\frac{1}{N_B(N_B-1)}\sum_{i=1}^{N_B}\left(\langle f\rangle_{B_i} - \langle f\rangle_B\right)^2.\]</span> If the blocks are independent, <span class="math inline">\(\frac{s_B^2}{N_B}\)</span> remains constant for increasing values of <span class="math inline">\(k\)</span>, although for large <span class="math inline">\(k\)</span> (low <span class="math inline">\(N_B\sim100\)</span>) statistical fluctuations emerge.</p>
<p>The integrated autocorrelation time can be infered from the binning analysis results. Being <span class="math display">\[\tau=\frac{1}{2}\frac{\frac{s_B^2}{N_B}(k\rightarrow \infty)}{\frac{s_B^2}{N_B}(k=1)}.\]</span> Bear in mind that the autocorrelation time can <strong>change between quantities</strong>.</p>
</section>
</section>
<section id="example---binning-analysis" class="level2">
<h2 class="anchored" data-anchor-id="example---binning-analysis">Example - Binning analysis</h2>
<p>Let us continue with our previous example and perform the binning analysis in order to properly infer the error and the autocorrelation time out of the Markov Chain that we have already generated.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bin_averages(x, bs):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Bins time-series `x` into `bs` chunks and takes means"</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    nb <span class="op">=</span> <span class="bu">len</span>(x)<span class="op">//</span>bs</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    bin_avg <span class="op">=</span> [np.mean(x[b<span class="op">*</span>bs:(b<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>bs]) <span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(nb)]</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.array(bin_avg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>ks <span class="op">=</span> [<span class="dv">2</span><span class="op">**</span>k <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">12</span>)]</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>errors, means, bin_avgs <span class="op">=</span> [], [], []</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> ks:</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    bin_avg <span class="op">=</span> bin_averages(energies, k)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    error <span class="op">=</span> np.sqrt(np.var(bin_avg)<span class="op">/</span><span class="bu">len</span>(bin_avg))</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    errors.append(error)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    means.append(bin_avg.mean())</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    bin_avgs.append(bin_avg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>plt.plot(ks, np.array(errors)<span class="op">**</span><span class="dv">2</span>, <span class="st">'o-'</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>plt.tick_params(labelsize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"$s_B^2/N_B$"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Bin size"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="VMC-intro-RBM_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>With the binning analysis, we see that the squared error converges for a bin size of <span class="math inline">\(\sim100\)</span>. For very large bin sizes, the low number of bins incurs some statistical fluctuations. Thus, the result and statistical errors are properly computed for bin sizes <span class="math inline">\(64\leq k\leq1000\)</span>. We can take any of these values as valid, although the smaller the bin sizes, the lower the overall computational cost. Hence, for future calculations, we will try to keep a bin size that is well converged but not too large, e.g.&nbsp;between <span class="math inline">\(100\)</span> and <span class="math inline">\(200\)</span>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>means[<span class="op">-</span><span class="dv">3</span>]<span class="sc">:.4f}</span><span class="ss"> +- </span><span class="sc">{</span>errors[<span class="op">-</span><span class="dv">3</span>]<span class="sc">:.4f}</span><span class="ss"> for k=</span><span class="sc">{</span>ks[<span class="op">-</span><span class="dv">3</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>-9.3152 +- 0.0632 for k=512</code></pre>
</div>
</div>
<p>As shown before, we can also use these results to infer the autocorrelation time.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>tau <span class="op">=</span> (errors[<span class="op">-</span><span class="dv">3</span>]<span class="op">/</span>errors[<span class="dv">0</span>])<span class="op">**</span><span class="dv">2</span><span class="op">;</span> tau</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>5.243713762799869</code></pre>
</div>
</div>
<p>Let us see the bin averages with the mean and statistical error.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>k_idx <span class="op">=</span> <span class="op">-</span><span class="dv">3</span> <span class="co"># Choose the bin size</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>bins <span class="op">=</span> np.arange(<span class="bu">len</span>(bin_avgs[k_idx]))</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>plt.scatter(bins, bin_avgs[k_idx], s<span class="op">=</span><span class="dv">50</span>, marker<span class="op">=</span><span class="st">'s'</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>plt.hlines(means[k_idx], bins[<span class="dv">0</span>], bins[<span class="op">-</span><span class="dv">1</span>], linestyles<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>plt.fill_between(bins, means[k_idx]<span class="op">-</span>errors[k_idx], means[k_idx]<span class="op">+</span>errors[k_idx], color<span class="op">=</span><span class="st">'k'</span>, alpha<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>plt.tick_params(labelsize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Bin size </span><span class="sc">{</span>ks[k_idx]<span class="sc">}</span><span class="ss">"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Local energy"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Bin"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)<span class="op">;</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>k_idx <span class="op">=</span> <span class="op">-</span><span class="dv">2</span> <span class="co"># Choose the bin size</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>bins <span class="op">=</span> np.arange(<span class="bu">len</span>(bin_avgs[k_idx]))</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>plt.scatter(bins, bin_avgs[k_idx], s<span class="op">=</span><span class="dv">50</span>, marker<span class="op">=</span><span class="st">'s'</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>plt.hlines(means[k_idx], bins[<span class="dv">0</span>], bins[<span class="op">-</span><span class="dv">1</span>], linestyles<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>plt.fill_between(bins, means[k_idx]<span class="op">-</span>errors[k_idx], means[k_idx]<span class="op">+</span>errors[k_idx], color<span class="op">=</span><span class="st">'k'</span>, alpha<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>plt.tick_params(labelsize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f"Bin size </span><span class="sc">{</span>ks[k_idx]<span class="sc">}</span><span class="ss">"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Local energy"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Bin"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="VMC-intro-RBM_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="VMC-intro-RBM_files/figure-html/cell-14-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="monte-carlo-optimization" class="level2">
<h2 class="anchored" data-anchor-id="monte-carlo-optimization">Monte Carlo optimization</h2>
<p>Now that we are able to reliably compute expectation values, we can use the same methods to optimize our variational ansatz according to a target function. In the previous examples, we have taken a completely random wave function, which is to be the starting point of our optimization process to find the ground state wave function.</p>
<p>We use the <strong>stochastic reconfiguration</strong> (SR) method {% cite SorellaJCP2007%} to optimize the parameters of the ansatz, which approximates the natural gradient {% cite AmariBook2006%}. Let our parametrized wavefunction be <span class="math inline">\(\Psi_\theta\)</span> with parameters <span class="math inline">\(\theta\)</span>. With SR, the parameter update rule is <span class="math inline">\(\theta_{t+1}=\theta_t + \alpha S_t^{-1}F_t\)</span>, where <span class="math inline">\(\alpha\)</span> is the learning rate, <span class="math inline">\(S\)</span> is an estimation of the Fischer information matrix and <span class="math inline">\(F\)</span> is an estimation of the gradient of a given cost function. The term <span class="math inline">\(S^{-1}F\)</span> is the natural gradient estimation of the cost function with respect to the parameters <span class="math inline">\(\theta\)</span>.</p>
<p>Given that the ground state is the one with the lowest possible energy of the system, our cost function will be the expected energy of the system under our parametrized wave function. This way, the parameters of our ansatz will be tuned to approximate the ground state of the system as best as possible.</p>
<p>Let us define the variational derivatives <span class="math inline">\(O\)</span> with respect to the <span class="math inline">\(k\)</span>-th parameter <span class="math inline">\(\theta_k\)</span> of our variational ansatz <span class="math inline">\(\Psi_\theta\)</span> as the log-derivative of the wave function <span class="math display">\[O_k(x) = \frac{\partial}{\partial\theta_k}\log\left(\Psi_\theta(x)\right)=\frac{1}{\Psi_\theta(x)}\frac{\partial\Psi_\theta(x)}{\partial\theta_k}\]</span> With this, we can define <span class="math inline">\(S\)</span> as the covariance matrix of the variational derivatives <span class="math inline">\(O_k\)</span> and compute <span class="math inline">\(F\)</span> in terms of the previously introduced local energy <span class="math inline">\(E_L(x)\)</span>: <span class="math display">\[ S_{kk'}=\langle O_k^*O_{k'}\rangle-\langle O_k^*\rangle\langle O_{k'}\rangle\]</span> <span class="math display">\[ F_k= \langle E_LO_k^*\rangle - \langle E_L\rangle\langle O_k^*\rangle\]</span> As an extra step, there can be introduced a regularization term to increase stability throught the optimization by removing the null diagonal terms of <span class="math inline">\(S\)</span> such that <span class="math inline">\(S_{kk} = S_{kk}+\lambda\)</span>.</p>
</section>
<section id="example---monte-carlo-optimization" class="level2">
<h2 class="anchored" data-anchor-id="example---monte-carlo-optimization">Example - Monte Carlo optimization</h2>
<p>Let us put everything together to find the ground state energy of the Ising Hamiltonian used in the previous examples. For the case of an RBM ansatz, the variational derivatives of the parameters can be obtained pretty easily, being: <span class="math display">\[O_{b_j}(s) = \frac{\partial}{\partial b_j}\log\left(\Psi(s)\right) = s_j \]</span> <span class="math display">\[O_{c_i}(s) = \frac{\partial}{\partial c_i}\log\left(\Psi(s)\right) = \tanh\left[\theta_i(s)\right]\]</span> <span class="math display">\[O_{W_{ij}}(s) = \frac{\partial}{\partial W_{ij}}\log\left(\Psi(s)\right) = s_j\tanh\left[\theta_i(s)\right]\]</span> Where <span class="math inline">\(\theta_i(s)\)</span> is the argument of the hyperbolic cosine <span class="math inline">\(\theta_i(s) = c_i + \sum_j W_{ij}s_j\)</span>.</p>
<p>We have seen that the autocorrelation time was <span class="math inline">\(\tau\sim 5\)</span>. In order to economize the simulation, rather than computing bin averages of <span class="math inline">\(\sim100-200\)</span> samples, we will draw samples every few steps larger than <span class="math inline">\(\tau\)</span> so that subsequent measurements are already uncorrelated.</p>
<p>We define our custom functions to compute the variational derivatives and covariances, as well as a function that will sample a bunch of states at once.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> variational_derivative(x, psi):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Computes variational derivatives for SR"</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    theta <span class="op">=</span> psi.c <span class="op">+</span> psi.W <span class="op">@</span> x</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    Ob <span class="op">=</span> x</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    Oc <span class="op">=</span> np.tanh(theta)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    Ow <span class="op">=</span> Oc[:, <span class="va">None</span>] <span class="op">@</span> x[<span class="va">None</span>, :]</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.concatenate((Ob, Oc, Ow.ravel()))</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> covariance(x1, x2):</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Computes the covariance between `x1` and `x2`."</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    samples <span class="op">=</span> x1.shape[<span class="dv">1</span>]</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    m1 <span class="op">=</span> np.mean(x1, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    m2 <span class="op">=</span> np.mean(x2, axis<span class="op">=</span><span class="dv">1</span>) <span class="cf">if</span> <span class="bu">len</span>(x2.shape)<span class="op">&gt;</span><span class="dv">1</span> <span class="cf">else</span> np.mean(x2)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (x1 <span class="op">@</span> x2.T)<span class="op">/</span>samples <span class="op">-</span> m1[:,<span class="va">None</span>] <span class="op">@</span> m2[<span class="va">None</span>,:]</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_block(psi, bs, x0<span class="op">=</span><span class="va">None</span>, n_flips<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Sample `bs` states according to `psi`."</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    state <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">2</span>, psi.n_visible) <span class="cf">if</span> x0 <span class="kw">is</span> <span class="va">None</span> <span class="cf">else</span> x0</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    states <span class="op">=</span> []</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(bs):</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>        spin_idx <span class="op">=</span> np.random.randint(<span class="dv">0</span>, psi.n_visible, n_flips)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>        new_state <span class="op">=</span> flip(state, spin_idx)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> np.random.random() <span class="op">&lt;=</span> np.<span class="bu">abs</span>(psi.p_ratio(state, new_state))<span class="op">**</span><span class="dv">2</span>:</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>            state <span class="op">=</span> deepcopy(new_state)   <span class="co"># Accept new state   </span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>        states.append(state)</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> states</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With <code>sample_block</code> we will be taking one energy sample every <span class="math inline">\(N=10\gg\tau\)</span> steps. However, we could also take the mini-block averages as samples, which can be easily implemented in the code below. Taking the mini-block average is, probably, a better practice, although it is more computationally expensive, provided that it still requires to compute the local energy for each state. Another way to lower the computational cost is by increasing the amount of spins that are flipped to propose new configurations.</p>
<p>It all boils down to a the trade-off between computational cost and accuracy. For this case, a sample every few steps works just fine. I encourage the reader to try out different block sizes, e.g.&nbsp;<span class="math inline">\(\text{bs}\in[1, 15]\)</span>, and test with mini-block averages and different number of spin flips. Keeping everything else constant, small block sizes should incur into slower and unstable convergence to the minimal energy due to the high correlation between samples. On the other side, excessively large block sizes suffer from the lack of statistics.</p>
<p>When comparing different parameters, remember to set a random seed in order to always start with the same initial condition.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>learning_iterations <span class="op">=</span> <span class="dv">275</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">1e-2</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>n_blocks <span class="op">=</span> <span class="dv">150</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>thermalise <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.1</span><span class="op">*</span>n_blocks)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>Nb <span class="op">=</span> n_blocks <span class="op">-</span> thermalise</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>bs <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>n_flips <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>energies <span class="op">=</span> []</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> it <span class="kw">in</span> tqdm(<span class="bu">range</span>(learning_iterations)):</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    EL, O <span class="op">=</span> np.zeros(Nb, dtype<span class="op">=</span><span class="bu">complex</span>), np.zeros((<span class="bu">len</span>(psi.params), Nb), dtype<span class="op">=</span><span class="bu">complex</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    states <span class="op">=</span> sample_block(psi, thermalise<span class="op">*</span>bs, n_flips<span class="op">=</span>n_flips)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    state <span class="op">=</span> states[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(Nb):</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>        batch <span class="op">=</span> sample_block(psi, bs, x0<span class="op">=</span>state, n_flips<span class="op">=</span>n_flips)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>        states <span class="op">+=</span> batch</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>        state <span class="op">=</span> batch[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>        EL[k] <span class="op">=</span> local_energy(state, psi)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>        O[:, k] <span class="op">=</span> variational_derivative(state, psi)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    energies.append(EL.mean())</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    F <span class="op">=</span> covariance(O.conj(), EL[<span class="va">None</span>,:])   <span class="co"># Gradient</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    S <span class="op">=</span> covariance(O.conj(), O)            <span class="co"># Fisher info</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    Sinv <span class="op">=</span> np.linalg.pinv(S, rcond<span class="op">=</span><span class="fl">1e-5</span>)   <span class="co"># (pseudo)Inversion</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>    d_params <span class="op">=</span> lr<span class="op">*</span>Sinv <span class="op">@</span> F</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>    psi.params <span class="op">-=</span> d_params.squeeze()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let us plot the expected energy over the optimization steps.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>plt.plot(np.real(energies))</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>plt.tick_params(labelsize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"$\langle H\rangle$"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Learning iteration"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="VMC-intro-RBM_files/figure-html/cell-18-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The algorithm has converged to the ground state energy at around 150 iterations. Let us see the local energies sampled during the last optimization step.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">5</span>))</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>plt.plot(np.real(EL))</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>plt.grid()</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>plt.tick_params(labelsize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="vs">r"$E_L$"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Sample"</span>, fontsize<span class="op">=</span><span class="dv">20</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="VMC-intro-RBM_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We can see how, by the end of the optimization, the wavefunction mainly provides the ground state and, with some small probability, other states are sampled. To report the ground state energy, we take the result of the last 100 optimization steps, analogously to the binning analysis (the imaginary part should average to zero).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>bins <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>energy <span class="op">=</span> np.mean(np.real(energies[<span class="op">-</span>bins:]))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>statistical_error <span class="op">=</span> np.std(energies[<span class="op">-</span>bins:])<span class="op">/</span>np.sqrt(bins)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The obtained energy is </span><span class="sc">{</span>energy<span class="sc">:.4f}</span><span class="ss">+-</span><span class="sc">{</span>statistical_error<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The obtained energy is -19.4827+-0.0086</code></pre>
</div>
</div>
<p>Notice that we have taken the quantum Ising model in the ferromagnetic phase. Therefore, the ground state is found when all spins are aligned (either all 0 or 1).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The ground state is </span><span class="sc">{</span>state<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The ground state is [1 1 1 1 1 1 1 1 1 1]</code></pre>
</div>
</div>
<p>We can compare this with exact diagonalization, provided that we are solving a small system, in order to see the actual real error. Let us build the Hamiltonian matrix and diagonlaize it.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tensor_prod(idx, s, size<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Tensor product of `s` acting on indexes `idx`. Fills rest with Id."</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    Id <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">0</span>],[<span class="dv">0</span>,<span class="dv">1</span>]])</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    idx, s <span class="op">=</span> np.array(idx), np.array(s)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    matrices <span class="op">=</span> [Id <span class="cf">if</span> k <span class="kw">not</span> <span class="kw">in</span> idx <span class="cf">else</span> s <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(size)]</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    prod <span class="op">=</span> matrices[<span class="dv">0</span>]</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, size):</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>        prod <span class="op">=</span> np.kron(prod, matrices[k])</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> prod</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>sx <span class="op">=</span> np.array([[<span class="dv">0</span>,<span class="dv">1</span>],[<span class="dv">1</span>,<span class="dv">0</span>]])</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>sz <span class="op">=</span> np.array([[<span class="dv">1</span>,<span class="dv">0</span>],[<span class="dv">0</span>,<span class="op">-</span><span class="dv">1</span>]])</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>H <span class="op">=</span> (J<span class="op">*</span><span class="bu">sum</span>([tensor_prod([k, k<span class="op">+</span><span class="dv">1</span>], sz, size<span class="op">=</span>N) <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(N<span class="op">-</span><span class="dv">1</span>)]) <span class="op">+</span> </span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>     B<span class="op">*</span><span class="bu">sum</span>([tensor_prod(k, sx, size<span class="op">=</span>N) <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(N)]))</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>e_vals, e_vecs <span class="op">=</span> np.linalg.eigh(H)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>relative_error <span class="op">=</span> np.<span class="bu">abs</span>((energy<span class="op">-</span>e_vals[<span class="dv">0</span>])<span class="op">/</span>e_vals[<span class="dv">0</span>])</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The exact ground state energy is </span><span class="sc">{</span>e_vals[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Relative error between variational energy </span><span class="sc">{</span>energy<span class="sc">:.4f}</span><span class="ss"> and exact solution </span><span class="sc">{</span>e_vals[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">: </span><span class="sc">{</span>relative_error<span class="op">*</span><span class="dv">100</span><span class="sc">:.4f}</span><span class="ss">%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>The exact ground state energy is -19.5310
Relative error between variational energy -19.4827 and exact solution -19.5310: 0.2473%</code></pre>
</div>
</div>
<p>We see that the error is of the order of <span class="math inline">\(0.2\%\)</span>, which means that our ansatz can accurately represent the exact ground state of the system at hand.</p>
<p>Hopefully, this was helpful to anyone starting with Monte Carlo methods :)</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<p>{% bibliography cited %}</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>